# Volume_controller_using_hand_gestures

We use the google trained model 'mediapipe' to detect hand movements, pose, face gestures etc.
Using Mediapipe library, we define certain constraints over the hand movements to define different different movements
We use one of those movements as a switch for our desired function. 
It also uses opencv library for change in video image type, draw on video image.
